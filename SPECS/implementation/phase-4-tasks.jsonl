{"id":"3","status":"pending","subject":"Rewrite HeartbeatManager GenServer (Section 4.1)","description":"Section 4.1 subtasks: - [ ] 4.1.1.1 Create `lib/observatory/gateway/heartbeat_manager.ex` with `use GenServer`, declare `@eviction_threshold_seconds 90` and `@check_interval_ms 30_000`, add `def start_link/1` that registers the process as `__MODULE__`, and implement `init/1` that calls `:timer.send_interval(@check_interval_ms, :check_heartbeats)` and returns `{:ok, %{}}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.1.1.2 Implement `def record_heartbeat(agent_id, cluster_id)` as `GenServer.call(__MODULE__, {:heartbeat, agent_id, cluster_id})` and the corresponding `handle_call/3` that inserts or replaces `agent_id => %{last_seen: DateTime.utc_now(), cluster_id: cluster_id}` in the state map and returns `{:reply, :ok, updated_state}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.1.1.3 Implement `handle_info(:check_heartbeats, state)` that calls `DateTime.utc_now()`, iterates every entry in state via `Enum.filter/2`, evicts agents where `DateTime.diff(now, last_seen, :second) > @eviction_threshold_seconds`, calls `Observatory.Gateway.CapabilityMap.remove_agent(agent_id)` for each evicted entry, logs each eviction at `:info` level with `agent_id` and `last_seen` fields, and returns `{:noreply, Map.drop(state, evicted_agent_ids)}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.1.1.4 Add `Observatory.Gateway.HeartbeatManager` to the application supervisor in `lib/observatory/application.ex` under the Gateway children group `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.1.2.1 Generate and populate an Ecto migration in `priv/repo/migrations/` that creates table `gateway_heartbeats` with columns: `agent_id text primary key`, `cluster_id text not null`, `last_seen_at datetime not null` `done_when: \"mix ecto.migrate && mix compile --warnings-as-errors\"` - [ ] 4.1.2.2 Create `lib/observatory/gateway/heartbeat_record.ex` under module `Observatory.Gateway.HeartbeatRecord` using `use Ecto.Schema`, define `schema \"gateway_heartbeats\" do` with `field :agent_id, :str","goal":"Section 4.1 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix compile --warnings-as-errors","mix ecto.migrate && mix compile --warnings-as-errors","mix test test/observatory_web/controllers/heartbeat_controller_test.exs","mix test test/observatory/gateway/heartbeat_manager_test.exs"],"priority":"high","blocked_by":[],"files":["lib/observatory_web/controllers/heartbeat_controller.ex","lib/observatory_web/router.ex","lib/observatory/application.ex","lib/observatory/gateway/heartbeat_manager.ex","lib/observatory/gateway/heartbeat_record.ex","test/observatory_web/controllers/heartbeat_controller_test.exs","test/observatory/gateway/heartbeat_manager_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","heartbeatmanager-genserver","section-4.1"],"roadmap_ref":"4.1","notes":""}
{"id":"2","status":"pending","subject":"Rewrite CronScheduler & DB Schema (Section 4.2)","description":"Section 4.2 subtasks: - [ ] 4.2.1.1 Create `lib/observatory/gateway/cron_scheduler.ex` with `use GenServer`, implement `start_link/1` that registers as `__MODULE__`, and implement `init/1` that queries all `cron_jobs` rows from the Repo, schedules timers for each using `Process.send_after(self(), {:fire_job, row.id, row.agent_id, row.payload}, max(delay_until_fire, 0))` where `delay_until_fire` is computed as `DateTime.diff(row.next_fire_at, DateTime.utc_now(), :millisecond)`, and returns `{:ok, %{jobs: %{}}}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.2.1.2 Implement `def schedule_once(agent_id, delay_ms, payload)` as a `GenServer.call` that returns `{:error, :invalid_delay}` when `delay_ms` is not a positive integer, otherwise inserts a `CronJob` Ecto record with `is_one_time: true`, `next_fire_at: DateTime.add(DateTime.utc_now(), delay_ms, :millisecond)`, and `payload: Jason.encode!(payload)`, then calls `Process.send_after/3` with the timer, and returns `:ok` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.2.1.3 Implement `handle_info({:fire_job, job_id, agent_id, payload_json}, state)` that decodes `payload_json` via `Jason.decode!/1`, calls `Phoenix.PubSub.broadcast(Observatory.PubSub, \"agent:#{agent_id}:scheduled\", decoded_payload)`, queries the `cron_jobs` row by `job_id`, and if `is_one_time: true` deletes the row from the Repo; for recurring jobs updates `next_fire_at` and re-schedules the timer; returns `{:noreply, state}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.2.1.4 Add `Observatory.Gateway.CronScheduler` to the application supervisor in `lib/observatory/application.ex` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.2.2.1 Generate and populate an Ecto migration in `priv/repo/migrations/` that creates table `cron_jobs` with columns: `id integer primary key autoincrement`, `agent_id text not null`, `schedule text`, `next_fire_at datetime not null`, `payload text not null`, `is_one_time boolean not null default false` `done_when: \"m","goal":"Section 4.2 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix compile --warnings-as-errors","mix ecto.migrate && mix compile --warnings-as-errors","mix test test/observatory/gateway/cron_scheduler_test.exs"],"priority":"high","blocked_by":["3"],"files":["lib/observatory/application.ex","lib/observatory/gateway/cron_job.ex","lib/observatory/gateway/cron_scheduler.ex","lib/observatory/gateway/schema_interceptor.ex","test/observatory/gateway/cron_scheduler_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","cronscheduler-db-schema","section-4.2"],"roadmap_ref":"4.2","notes":""}
{"id":"6","status":"pending","subject":"Rewrite WebhookRouter Retry & DLQ (Section 4.3)","description":"Section 4.3 subtasks: - [ ] 4.3.1.1 Create `lib/observatory/gateway/webhook_router.ex` with `use GenServer`, declare `@retry_schedule_seconds [30, 120, 600, 3600, 21600]` and `@poll_interval_ms 5_000`, implement `start_link/1` registered as `__MODULE__`, implement `init/1` that calls startup re-queuing (calls private `requeue_undelivered/0`) and schedules the first poll via `Process.send_after(self(), :poll, @poll_interval_ms)`, returns `{:ok, %{}}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.3.1.2 Implement `handle_info(:poll, state)` that queries `Repo.all(from d in WebhookDelivery, where: d.status in [\"pending\", \"failed\"] and d.next_retry_at <= ^DateTime.utc_now(), limit: 5)`, calls `attempt_delivery/1` for each, re-schedules the next poll via `Process.send_after(self(), :poll, @poll_interval_ms)`, returns `{:noreply, state}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.3.1.3 Implement private `attempt_delivery/1` that issues an HTTP POST to `delivery.target_url` with body `delivery.payload` and header `X-Observatory-Signature: sha256=#{delivery.signature}` using `Req.post/2` or `:httpc.request/4`; on HTTP 2xx calls `mark_delivered/1` to set `status: \"delivered\"`; on failure calls `schedule_retry/1` that increments `attempt_count`, looks up the delay via `Enum.at(@retry_schedule_seconds, delivery.attempt_count)`, sets `next_retry_at: DateTime.add(DateTime.utc_now(), delay, :second)` and `status: \"failed\"`, or if `attempt_count >= 5` sets `status: \"dead\"` and broadcasts `%WebhookDLQEvent{webhook_id: delivery.webhook_id}` on `\"gateway:webhooks\"` via `Phoenix.PubSub.broadcast/3` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.3.1.4 Implement private `requeue_undelivered/0` that queries all rows with `status IN (\"pending\", \"failed\")` on startup; for each row whose `next_retry_at` is in the past, updates `next_retry_at` to `DateTime.utc_now()` so the first poll cycle dispatches it immediately; leaves rows with future `next_retry_at` unchanged `done_when: \"mix","goal":"Section 4.3 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix compile --warnings-as-errors","mix ecto.migrate && mix compile --warnings-as-errors","mix test test/observatory_web/controllers/webhook_controller_test.exs","mix test test/observatory/gateway/webhook_deliveries_test.exs","mix test test/observatory/gateway/webhook_router_test.exs"],"priority":"high","blocked_by":["2"],"files":["lib/observatory_web/controllers/webhook_controller.ex","lib/observatory_web/router.ex","lib/observatory/application.ex","lib/observatory/gateway/webhook_delivery.ex","lib/observatory/gateway/webhook_router.ex","test/observatory_web/controllers/webhook_controller_test.exs","test/observatory/gateway/webhook_deliveries_test.exs","test/observatory/gateway/webhook_router_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","webhookrouter-retry-dlq","section-4.3"],"roadmap_ref":"4.3","notes":""}
{"id":"5","status":"pending","subject":"Rewrite HITLRelay State Machine (Section 4.4)","description":"Section 4.4 subtasks: - [ ] 4.4.1.1 Create `lib/observatory/gateway/hitl_relay.ex` with `use GenServer`, implement `start_link/1` registered as `__MODULE__`, implement `init/1` that creates the ETS table via `:ets.new(:hitl_buffer, [:ordered_set, :public, :named_table])` and returns `{:ok, %{sessions: %{}}}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.4.1.2 Implement `def pause(session_id, agent_id, operator_id, reason)` as `GenServer.call(__MODULE__, {:pause, session_id, agent_id, operator_id, reason})` and the corresponding `handle_call/3` that (a) checks whether `session_id` is already `:paused` in state and returns `{:reply, {:ok, :already_paused}, state}` if so; (b) otherwise transitions the session to `:paused` in state, broadcasts `%HITLGateOpenEvent{session_id: session_id, agent_id: agent_id, operator_id: operator_id, reason: reason, timestamp: DateTime.utc_now()}` on `\"session:hitl:#{session_id}\"` via `Phoenix.PubSub.broadcast/3`, and returns `{:reply, :ok, updated_state}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.4.1.3 Implement `def unpause(session_id, agent_id, operator_id)` as `GenServer.call(__MODULE__, {:unpause, session_id, agent_id, operator_id})` and the corresponding `handle_call/3` that (a) flushes the ETS buffer for key `{session_id, agent_id}` by looking up the ordered list, broadcasting each `%DecisionLog{}` sequentially on the standard DecisionLog PubSub topic via `Phoenix.PubSub.broadcast/3`, deleting the ETS entry via `:ets.delete/2` after the flush, logging any crash at `:error` level with `session_id`; (b) transitions the session to `:normal` in state; (c) broadcasts `%HITLGateCloseEvent{session_id: session_id, agent_id: agent_id, operator_id: operator_id, timestamp: DateTime.utc_now()}` on `\"session:hitl:#{session_id}\"`; (d) returns `{:reply, :ok, updated_state}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.4.1.4 Add `Observatory.Gateway.HITLRelay` to the application supervisor in `lib/observatory/application.ex` `done_whe","goal":"Section 4.4 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix compile --warnings-as-errors","mix test test/observatory/gateway/hitl_relay_test.exs"],"priority":"high","blocked_by":["6"],"files":["lib/observatory/application.ex","lib/observatory/gateway/hitl_events.ex","lib/observatory/gateway/hitl_relay.ex","test/observatory/gateway/hitl_relay_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","hitlrelay-state-machine","section-4.4"],"roadmap_ref":"4.4","notes":""}
{"id":"4","status":"pending","subject":"Rewrite HITL HTTP Endpoints & Auth (Section 4.5)","description":"Section 4.5 subtasks: - [ ] 4.5.1.1 Create `lib/observatory/plugs/operator_auth.ex` under module `Observatory.Plugs.OperatorAuth` with `@behaviour Plug`, implement `init/1` that returns opts unchanged, implement `call/2` that reads `conn |> get_req_header(\"x-observatory-operator-id\") |> List.first()`, applies `String.trim/1`, halts with `conn |> put_status(401) |> json(%{status: \"error\", reason: \"missing_operator_id\"}) |> halt()` if the trimmed value is empty or nil, otherwise assigns the value to `conn.assigns[:operator_id]` via `assign(conn, :operator_id, trimmed_value)` and returns `conn` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.5.2.1 Create `lib/observatory_web/controllers/hitl_controller.ex` under module `ObservatoryWeb.HITLController`; implement `def pause(conn, params)` that validates `params` contains `\"agent_id\"`, `\"operator_id\"`, and `\"reason\"` (all non-empty strings), returns HTTP 422 `{\"status\": \"error\", \"reason\": \"missing_required_field: #{field}\"}` for the first missing field, and on success calls `HITLRelay.pause(session_id, agent_id, operator_id, reason)` where `session_id` is `conn.path_params[\"session_id\"]` and returns `json(conn, %{status: \"ok\"})` on `:ok` or `json(conn, %{status: \"ok\", note: \"already_paused\"})` on `{:ok, :already_paused}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.5.2.2 In `ObservatoryWeb.HITLController`, implement `def unpause(conn, params)` validating `\"agent_id\"` and `\"operator_id\"`, calling `HITLRelay.unpause/3`; implement `def rewrite(conn, params)` validating `\"agent_id\"`, `\"operator_id\"`, `\"original_trace_id\"`, and `\"new_content\"`, calling `HITLRelay.rewrite/5` and returning HTTP 422 `{\"status\": \"error\", \"reason\": \"trace_id_not_found_in_buffer\"}` on `{:error, :trace_id_not_found_in_buffer}`; implement `def inject(conn, params)` validating `\"agent_id\"`, `\"operator_id\"`, and `\"prompt\"`, calling `HITLRelay.inject/4`; all success paths return `json(conn, %{status: \"ok\"})` `done_when: \"mix compile --warnings-as-errors\"` -","goal":"Section 4.5 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix ash.migrate && mix compile --warnings-as-errors","mix compile --warnings-as-errors","mix test test/observatory_web/controllers/hitl_controller_test.exs"],"priority":"high","blocked_by":["5"],"files":["lib/observatory_web/controllers/hitl_controller.ex","lib/observatory_web/router.ex","lib/observatory/gateway/hitl_intervention_event.ex","lib/observatory/plugs/operator_auth.ex","test/observatory_web/controllers/hitl_controller_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","hitl-http-endpoints-auth","section-4.5"],"roadmap_ref":"4.5","notes":""}
{"id":"1","status":"pending","subject":"Rewrite Auto-Pause & Operator Actions (Section 4.6)","description":"Section 4.6 subtasks: - [ ] 4.6.1.1 In `lib/observatory/gateway/schema_interceptor.ex`, add a private function `maybe_auto_pause/1` that receives a `%DecisionLog{}` struct and checks `log.control && log.control.hitl_required == true`; when true, calls `HITLRelay.pause(log.meta.cluster_id, log.identity.agent_id, \"system\", \"hitl_required_flag\")`, then calls `HITLRelay.buffer_message(session_id, log.identity.agent_id, log)` to place the triggering DecisionLog into the buffer, and returns `{:paused, log}`; when false or nil, returns `{:normal, log}` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.6.1.2 In the SchemaInterceptor's post-validation dispatch pipeline, call `maybe_auto_pause(decision_log)` first; on `{:paused, _log}`, skip the downstream PubSub broadcast for the DecisionLog (it is in the buffer); on `{:normal, log}`, proceed with the existing broadcast path including the `maybe_schedule_reminder/1` call from section 4.2.3 `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4.6.1.3 Write a test in `test/observatory/gateway/schema_interceptor_test.exs` (or create this file if absent) verifying that a validated DecisionLog with `control.hitl_required: true` triggers a `HITLGateOpenEvent` broadcast on `\"session:hitl:#{session_id}\"` and is NOT broadcast on the standard DecisionLog PubSub topic until `HITLRelay.unpause/3` is called `done_when: \"mix test test/observatory/gateway/schema_interceptor_test.exs\"` - [ ] 4.6.2.1 Create `lib/observatory_web/live/session_drilldown_live.ex` under module `ObservatoryWeb.SessionDrilldownLive` (or locate the existing session detail LiveView in the project); add `Phoenix.PubSub.subscribe(Observatory.PubSub, \"session:hitl:#{session_id}\")` in `mount/3`; implement `handle_info(%HITLGateOpenEvent{} = event, socket)` that sets `socket.assigns[:hitl_gate_open] = true` and `socket.assigns[:hitl_event] = event`; implement `handle_info(%HITLGateCloseEvent{}, socket)` that clears `hitl_gate_open` `done_when: \"mix compile --warnings-as-errors\"` - [ ] 4","goal":"Section 4.6 compiles from scratch matching its FRD exactly","acceptance_criteria":["mix compile --warnings-as-errors","mix test test/observatory_web/live/session_drilldown_live_test.exs","mix test test/observatory/gateway/hitl_relay_test.exs","mix test test/observatory/gateway/schema_interceptor_test.exs"],"priority":"high","blocked_by":["4"],"files":["lib/observatory_web/live/session_drilldown_live.ex","lib/observatory/gateway/schema_interceptor.ex","test/observatory_web/live/session_drilldown_live_test.exs","test/observatory/gateway/hitl_relay_test.exs","test/observatory/gateway/schema_interceptor_test.exs"],"done_when":"mix compile --warnings-as-errors","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","auto-pause-operator-actions","section-4.6"],"roadmap_ref":"4.6","notes":""}
{"id":"7","status":"pending","subject":"Generate migrations and run full test suite (Phase 4 final)","description":"Final integration task for Phase 4. Generate any pending migrations, apply them, and run the complete test suite with zero failures and zero warnings. Adapt commands to the project build system.","goal":"All Phase 4 changes integrated, full test suite green","acceptance_criteria":["All pending migrations/schema changes applied","Full test suite passes with 0 failures","Build passes with zero warnings"],"priority":"critical","blocked_by":["1"],"files":[],"done_when":"echo Verify: build clean + tests green","owner":"","created":"2026-02-22T13:16:57Z","updated":"2026-02-22T13:16:57Z","tags":["phase-4","migration","final"],"roadmap_ref":"4.final","notes":"Blocks on ALL other tasks. Run all schema changes and tests in one final pass."}
